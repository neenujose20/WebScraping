{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "from urllib.request import urlopen\n",
    "import requests \n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8539c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.8',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "   'sec-ch-ua-platform': '\"macOS\"',\n",
    "   'sec-fetch-dest': 'empty',\n",
    "   'sec-fetch-mode': 'cors',\n",
    "   'sec-fetch-site': 'same-origin'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceldata = pd.read_excel(\"Udemy courses excel path\",sheet_name = \"urls\")\n",
    "Udemy_urls = [] \n",
    "for idx in exceldata.index:\n",
    "    Udemy_url = exceldata['course url'][idx]\n",
    "    Udemy_urls.append(Udemy_url)\n",
    "Udemy_urls = list(set(Udemy_urls)) # removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_url = \"https://www.udemy.com\"\n",
    "\n",
    "# Initialize lists\n",
    "Instructor_url = []\n",
    "Course_url = []\n",
    "Instructor_name = []\n",
    "Instructor_rating = []\n",
    "No_of_reviews = []\n",
    "No_of_students = []\n",
    "No_of_courses = []\n",
    "Linkedin_url = []\n",
    "Youtube_url = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for url in Udemy_urls:\n",
    "    count += 1\n",
    "    print(count, url)\n",
    "\n",
    "    try:\n",
    "        # Perform initial requests and parsing\n",
    "        r = requests.Session().get(url, headers=req_headers, timeout=(5, 60))\n",
    "        soup = BS(r.content, 'html.parser')\n",
    "\n",
    "        all_urls = [a['href'] for a in soup('a') if a.has_attr('href')]\n",
    "        regex = r\"^/user/?\"\n",
    "\n",
    "        \n",
    "        user_url = [u for u in all_urls if re.match(regex, u)]\n",
    "        instructor_url = domain_url + user_url[0] if user_url else \"N/A\"\n",
    "\n",
    "        if instructor_url != \"N/A\":\n",
    "            r2 = requests.Session().get(instructor_url, headers=req_headers, timeout=(5, 60))\n",
    "            soup2 = BS(r2.content, 'html.parser')\n",
    "\n",
    "            instructor_name, no_of_students, instructor_rating, no_of_reviews, no_of_courses = None, None, None, None, None\n",
    "\n",
    "            all_urls = [a['href'] for a in soup2('a')  if a.has_attr('href')]\n",
    "\n",
    "            regex_linked_in = r\"^https://linkedin.com/?\"\n",
    "            linkedin_url = [u for u in all_urls if re.match(regex_linked_in, u)]\n",
    "\n",
    "            if len(linkedin_url)!=0:\n",
    "                Linkedin_url.append(linkedin_url[0])\n",
    "            else:\n",
    "                Linkedin_url.append(\"\")\n",
    "\n",
    "            regex_youtube = r\"^https://www.youtube.com/?\"\n",
    "            youtube_url = [u for u in all_urls if re.match(regex_youtube, u)]\n",
    "\n",
    "            if len(youtube_url)!=0:\n",
    "                Youtube_url.append(youtube_url[0])\n",
    "            else:\n",
    "                Youtube_url.append(\"\")\n",
    "\n",
    "\n",
    "            instructor_stats = soup.find('div',attrs={'class':'instructor--instructor__image-and-stats--1MRZH'})\n",
    "            instructor_name = instructor_stats.find('img')['alt']\n",
    "\n",
    "\n",
    "            stats = instructor_stats.findAll('div',attrs={'class':'ud-block-list-item ud-block-list-item-small ud-block-list-item-tight ud-block-list-item-neutral ud-text-sm'}) if instructor_stats.find('div') else None\n",
    "\n",
    "            for i in stats:\n",
    "\n",
    "                text = i.get_text()\n",
    "                if 'Instructor Rating' in text:\n",
    "                    instructor_rating = text.split(' ')[0]   \n",
    "                elif 'Reviews' in text:\n",
    "                    no_of_reviews = text.split(' ')[0]\n",
    "                elif 'Students' in text:\n",
    "                    no_of_students = text.split(' ')[0]\n",
    "                elif 'Courses' in text:\n",
    "                    no_of_courses = text.split(' ')[0]\n",
    "\n",
    "            if instructor_name != None:         \n",
    "                Instructor_name.append(instructor_name)\n",
    "            else:\n",
    "                Instructor_name.append(\"\")\n",
    "\n",
    "\n",
    "            if instructor_rating != None:         \n",
    "                Instructor_rating.append(instructor_rating)\n",
    "            else:\n",
    "                Instructor_rating.append(\"\")\n",
    "\n",
    "\n",
    "            if no_of_reviews != None:         \n",
    "                No_of_reviews.append(no_of_reviews)\n",
    "            else:\n",
    "                No_of_reviews.append(\"\")\n",
    "\n",
    "\n",
    "            if no_of_students != None:         \n",
    "                No_of_students.append(no_of_students)\n",
    "            else:\n",
    "                No_of_students.append(\"\")\n",
    "\n",
    "\n",
    "            if no_of_courses != None:         \n",
    "                No_of_courses.append(no_of_courses)\n",
    "            else:\n",
    "                No_of_courses.append(\"\")\n",
    "            \n",
    "            Course_url.append(url)\n",
    "            Instructor_url.append(instructor_url)\n",
    "\n",
    "        else:\n",
    "            Course_url.append(url)\n",
    "            Instructor_url.append(instructor_url)\n",
    "            Linkedin_url.append(\"N/A\")\n",
    "            Youtube_url.append(\"N/A\")\n",
    "            Instructor_name.append(\"N/A\") \n",
    "            Instructor_rating.append(\"N/A\")\n",
    "            No_of_reviews.append(\"N/A\")\n",
    "            No_of_students.append(\"N/A\")\n",
    "            No_of_courses.append(\"N/A\")\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timeout occurred\")\n",
    "        # Handle timeout error here if needed\n",
    "\n",
    "# Ensure all lists have the same length before further processing\n",
    "assert (\n",
    "    len(Instructor_url)\n",
    "    == len(Course_url)\n",
    "    == len(Instructor_name)\n",
    "    == len(Instructor_rating)\n",
    "    == len(No_of_reviews)\n",
    "    == len(No_of_students)\n",
    "    == len(No_of_courses)\n",
    "    == len(Linkedin_url)\n",
    "    == len(Youtube_url)\n",
    "), \"All arrays must have the same length\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc755917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'Udemy course URL':Course_url,\n",
    "                          'Instructor URL':Instructor_url,\n",
    "                          'Intructor name':Instructor_name,\n",
    "                          'Instructor rating':Instructor_rating,\n",
    "                          'Number of reviews':No_of_reviews,\n",
    "                          'Number of students':No_of_students,\n",
    "                          'Number of courses':No_of_courses,\n",
    "                          'LinkedIN URL': Linkedin_url,\n",
    "                          'Youtube URL': Youtube_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d234cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Scraped_udemy_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAfiltered_df = df[df[\"Instructor URL\"] != \"N/A\"]\n",
    "condition_2 = (NAfiltered_df[\"LinkedIN URL\"] != \"\") & (NAfiltered_df[\"Youtube URL\"] != \"\")\n",
    "filtered_df = NAfiltered_df[condition_2]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('Scraped_filtered_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54522db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
